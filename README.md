# BERT Pytorch Implementation
A Pytorch Implementation of the paper "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding".   
I used Transformer Encoder from my [Transformer Implementation](https://github.com/yonghee12/transformer_torch).

## References
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
- [Attention Is All You Need, Vaswani et al.](https://arxiv.org/abs/1706.03762)
- [BERT, Google Research](https://github.com/google-research/bert)
- [BERT-pytorch, Junseong Kim](https://github.com/codertimo/BERT-pytorch)
- [Transformers, Huggingface](https://github.com/huggingface/transformers)

## Author
- This repository is developed and maintained by Yonghee Cheon (yonghee.cheon@gmail.com).      
- It can be found here: https://github.com/yonghee12/bert_torch
- Linkedin Profile: https://www.linkedin.com/in/yonghee-cheon-7b90b116a/